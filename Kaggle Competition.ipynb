{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/kaggle/input/m5-forecasting-accuracy/calendar.csv' does not exist: b'/kaggle/input/m5-forecasting-accuracy/calendar.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bbc9e0b46553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m \u001b[0mdates_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/m5-forecasting-accuracy/calendar.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0mprices_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/m5-forecasting-accuracy/sell_prices.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0msales_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/kaggle/input/m5-forecasting-accuracy/calendar.csv' does not exist: b'/kaggle/input/m5-forecasting-accuracy/calendar.csv'"
     ]
    }
   ],
   "source": [
    "# Kaggle Competition\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm as tqdm\n",
    "\n",
    "\n",
    "class WRMSSEEvaluator(object):\n",
    "    # https://www.kaggle.com/dhananjay3/wrmsse-evaluator-with-extra-features    \n",
    "    group_ids = (\n",
    "        'all_id', 'state_id', 'store_id', 'cat_id', 'dept_id', 'item_id',\n",
    "        ['state_id', 'cat_id'],  ['state_id', 'dept_id'], ['store_id', 'cat_id'],\n",
    "        ['store_id', 'dept_id'], ['item_id', 'state_id'], ['item_id', 'store_id']\n",
    "    )\n",
    "\n",
    "    def __init__(self, \n",
    "                 train_df: pd.DataFrame, \n",
    "                 valid_df: pd.DataFrame, \n",
    "                 calendar: pd.DataFrame, \n",
    "                 prices: pd.DataFrame):\n",
    "        '''\n",
    "        intialize and calculate weights\n",
    "        '''\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.train_target_columns = [i for i in self.train_df.columns if i.startswith('d_')]\n",
    "        self.weight_columns = self.train_df.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        self.train_df['all_id'] = \"all\"\n",
    "\n",
    "        self.id_columns = [i for i in self.train_df.columns if not i.startswith('d_')]\n",
    "        self.valid_target_columns = [i for i in self.valid_df.columns if i.startswith('d_')]\n",
    "\n",
    "        if not all([c in self.valid_df.columns for c in self.id_columns]):\n",
    "            self.valid_df = pd.concat([self.train_df[self.id_columns], self.valid_df],\n",
    "                                      axis=1, \n",
    "                                      sort=False)\n",
    "        self.train_series = self.trans_30490_to_42840(self.train_df, \n",
    "                                                      self.train_target_columns, \n",
    "                                                      self.group_ids)\n",
    "        self.valid_series = self.trans_30490_to_42840(self.valid_df, \n",
    "                                                      self.valid_target_columns, \n",
    "                                                      self.group_ids)\n",
    "        self.weights = self.get_weight_df()\n",
    "        self.scale = self.get_scale()\n",
    "        self.train_series = None\n",
    "        self.train_df = None\n",
    "        self.prices = None\n",
    "        self.calendar = None\n",
    "\n",
    "    def get_scale(self):\n",
    "        '''\n",
    "        scaling factor for each series ignoring starting zeros\n",
    "        '''\n",
    "        scales = []\n",
    "        for i in tqdm(range(len(self.train_series))):\n",
    "            series = self.train_series.iloc[i].values\n",
    "            series = series[np.argmax(series!=0):]\n",
    "            scale = ((series[1:] - series[:-1]) ** 2).mean()\n",
    "            scales.append(scale)\n",
    "        return np.array(scales)\n",
    "    \n",
    "    def get_name(self, i):\n",
    "        '''\n",
    "        convert a str or list of strings to unique string \n",
    "        used for naming each of 42840 series\n",
    "        '''\n",
    "        if type(i) == str or type(i) == int:\n",
    "            return str(i)\n",
    "        else:\n",
    "            return \"--\".join(i)\n",
    "    \n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        returns weights for each of 42840 series in a dataFrame\n",
    "        \"\"\"\n",
    "        day_to_week = self.calendar.set_index(\"d\")[\"wm_yr_wk\"].to_dict()\n",
    "        weight_df = self.train_df[[\"item_id\", \"store_id\"] + self.weight_columns].set_index(\n",
    "            [\"item_id\", \"store_id\"]\n",
    "        )\n",
    "        weight_df = (\n",
    "            weight_df.stack().reset_index().rename(columns={\"level_2\": \"d\", 0: \"value\"})\n",
    "        )\n",
    "        weight_df[\"wm_yr_wk\"] = weight_df[\"d\"].map(day_to_week)\n",
    "        weight_df = weight_df.merge(\n",
    "            self.prices, how=\"left\", on=[\"item_id\", \"store_id\", \"wm_yr_wk\"]\n",
    "        )\n",
    "        weight_df[\"value\"] = weight_df[\"value\"] * weight_df[\"sell_price\"]\n",
    "        weight_df = weight_df.set_index([\"item_id\", \"store_id\", \"d\"]).unstack(level=2)[\n",
    "            \"value\"\n",
    "        ]\n",
    "        weight_df = weight_df.loc[\n",
    "            zip(self.train_df.item_id, self.train_df.store_id), :\n",
    "        ].reset_index(drop=True)\n",
    "        weight_df = pd.concat(\n",
    "            [self.train_df[self.id_columns], weight_df], axis=1, sort=False\n",
    "        )\n",
    "        weights_map = {}\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids, leave=False)):\n",
    "            lv_weight = weight_df.groupby(group_id)[self.weight_columns].sum().sum(axis=1)\n",
    "            lv_weight = lv_weight / lv_weight.sum()\n",
    "            for i in range(len(lv_weight)):\n",
    "                weights_map[self.get_name(lv_weight.index[i])] = np.array(\n",
    "                    [lv_weight.iloc[i]]\n",
    "                )\n",
    "        weights = pd.DataFrame(weights_map).T / len(self.group_ids)\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def trans_30490_to_42840(self, df, cols, group_ids, dis=False):\n",
    "        '''\n",
    "        transform 30490 sries to all 42840 series\n",
    "        '''\n",
    "        series_map = {}\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids, leave=False, disable=dis)):\n",
    "            tr = df.groupby(group_id)[cols].sum()\n",
    "            for i in range(len(tr)):\n",
    "                series_map[self.get_name(tr.index[i])] = tr.iloc[i].values\n",
    "        return pd.DataFrame(series_map).T\n",
    "    \n",
    "    def get_rmsse(self, valid_preds) -> pd.Series:\n",
    "        '''\n",
    "        returns rmsse scores for all 42840 series\n",
    "        '''\n",
    "        score = ((self.valid_series - valid_preds) ** 2).mean(axis=1)\n",
    "        rmsse = (score / self.scale).map(np.sqrt)\n",
    "        return rmsse\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds],\n",
    "                                axis=1, \n",
    "                                sort=False)\n",
    "        valid_preds = self.trans_30490_to_42840(valid_preds, \n",
    "                                                self.valid_target_columns, \n",
    "                                                self.group_ids, \n",
    "                                                True)\n",
    "        self.rmsse = self.get_rmsse(valid_preds)\n",
    "        self.contributors = pd.concat([self.weights, self.rmsse], \n",
    "                                      axis=1, \n",
    "                                      sort=False).prod(axis=1)\n",
    "        return np.sum(self.contributors)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dates_df = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\n",
    "prices_df = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sell_prices.csv')\n",
    "sales_df = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv')\n",
    "\n",
    "sample_submission = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv')\n",
    "\n",
    "sales_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sales_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-28bb00c39448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msales_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msales_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_days_amount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m valid_evaluator = WRMSSEEvaluator(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sales_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "sales_array = sales_df.iloc[:, 6:].values\n",
    "\n",
    "val_days_amount = 28\n",
    "\n",
    "valid_evaluator = WRMSSEEvaluator(\n",
    "    sales_df.iloc[:, :-val_days_amount],\n",
    "    sales_df.iloc[:, -val_days_amount:],\n",
    "    dates_df,\n",
    "    prices_df\n",
    ")\n",
    "\n",
    "\n",
    "def get_weighted_moving_average_prediction_online(train_sales, beta=0.5):\n",
    "    result = train_sales[:, 0]\n",
    "    for n in range(1, train_sales.shape[1]):\n",
    "        result = beta * train_sales[:, n] + (1 - beta) * result\n",
    "    return result\n",
    "\n",
    "X_train = sales_array[:, :-val_days_amount]\n",
    "X_val = sales_array[:, -val_days_amount:]\n",
    "\n",
    "first_val_day_index = int(sales_df.columns[-val_days_amount].partition('_')[2])\n",
    "\n",
    "all_wrmse_scores = []\n",
    "day_columns = [f'd_{i}' for i in range(first_val_day_index, first_val_day_index + val_days_amount)]\n",
    "\n",
    "for beta in tqdm(np.linspace(0.1, 0.9, 9), leave=False):\n",
    "    result = get_weighted_moving_average_prediction_online(X_train, beta)\n",
    "    result = np.array([result] * val_days_amount).T\n",
    "    result_df = pd.DataFrame(result, columns=day_columns)\n",
    "    wrmse_score = valid_evaluator.score(result_df)\n",
    "    all_wrmse_scores.append(wrmse_score)\n",
    "    \n",
    "    del result_df\n",
    "\n",
    "plt.plot(np.linspace(0.1, 0.9, 9), all_wrmse_scores)\n",
    "plt.xlabel(r'$\\beta$')\n",
    "plt.ylabel('wrmsse')\n",
    "\n",
    "\n",
    "\n",
    "all_wrmse_scores = []\n",
    "day_columns = [f'd_{i}' for i in range(first_val_day_index, first_val_day_index + val_days_amount)]\n",
    "\n",
    "\n",
    "for beta in np.linspace(0.01, 0.1, 5):\n",
    "    result = get_weighted_moving_average_prediction_online(X_train, beta)\n",
    "    result = np.array([result] * val_days_amount).T\n",
    "    result_df = pd.DataFrame(result, columns=day_columns)\n",
    "    wrmse_score = valid_evaluator.score(result_df)\n",
    "    all_wrmse_scores.append(wrmse_score)\n",
    "    \n",
    "    del result_df\n",
    "\n",
    "plt.plot(np.linspace(0.01, 0.1, 5), all_wrmse_scores)\n",
    "plt.xlabel(r'$\\beta$')\n",
    "plt.ylabel('wrmsse')\n",
    "\n",
    "\n",
    "chosen_beta = 0.05\n",
    "\n",
    "def get_weighted_moving_average_prediction_online_with_season(\n",
    "    train_sales, beta=0.5, season_d=7, gamma=0.1,\n",
    "):\n",
    "    result = train_sales[:, 0]\n",
    "    season_result = [train_sales[:, i] for i in range(season_d)]\n",
    "    for n in range(1, train_sales.shape[1]):\n",
    "        result = beta * train_sales[:, n] + (1 - beta) * result\n",
    "        if n >= season_d:\n",
    "            season_result[n % season_d] = gamma * train_sales[:, n] + (1 - gamma) * season_result[n % season_d]\n",
    "    return result, season_result\n",
    "\n",
    "season_d = 7\n",
    "result, season_result = get_weighted_moving_average_prediction_online_with_season(\n",
    "    X_train, beta=0.05, season_d=season_d, gamma=0.25\n",
    ")\n",
    "\n",
    "\n",
    "all_wrmse_scores = []\n",
    "day_columns = [f'd_{i}' for i in range(first_val_day_index, first_val_day_index + val_days_amount)]\n",
    "\n",
    "\n",
    "for alpha in [0.1, 0.2, 0.3, 0.4]:\n",
    "    final_result = np.array([result] * val_days_amount).T\n",
    "    for i in range(final_result.shape[1]):\n",
    "        season_index = (X_train.shape[1] + i) % season_d\n",
    "        final_result[:, i] = final_result[:, i] * alpha + (1-alpha) * season_result[season_index]\n",
    "    result_df = pd.DataFrame(final_result, columns=day_columns)\n",
    "    wrmse_score = valid_evaluator.score(result_df)\n",
    "    all_wrmse_scores.append(wrmse_score)\n",
    "    \n",
    "    del result_df\n",
    "\n",
    "plt.plot([0.1, 0.2, 0.3, 0.4], all_wrmse_scores)\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('wrmsse')\n",
    "\n",
    "\n",
    "alpha = 0.01\n",
    "beta = 0.05\n",
    "gamma = 0.25\n",
    "\n",
    "\n",
    "result, season_result = get_weighted_moving_average_prediction_online_with_season(\n",
    "    X_train, beta=beta, season_d=7, gamma=gamma\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "val_days_amount = 56\n",
    "\n",
    "\n",
    "final_result = np.array([result] * val_days_amount).T\n",
    "for i in range(final_result.shape[1]):\n",
    "    season_index = (X_train.shape[1] + i) % 7\n",
    "    final_result[:, i] = final_result[:, i] * alpha + (1-alpha) * season_result[season_index]\n",
    "\n",
    "n_objects = X_train.shape[0]\n",
    "day_columns = [f'F{i}' for i in range(1, 29)]\n",
    "\n",
    "sample_submission.loc[:n_objects - 1, day_columns] = final_result[:, :28]\n",
    "sample_submission.loc[n_objects:, day_columns] = final_result[:, 28:]\n",
    "\n",
    "sample_submission.to_csv('/kaggle/working/baseline_ma7days.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
